import pandas as pd
import cv2
import requests
import numpy as np
import pickle
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm

orb = cv2.ORB_create(nfeatures=500)


def url_to_image(url):
    """TÃ©lÃ©charge une image depuis une URL et la convertit pour OpenCV"""
    try:
        # 1. On tÃ©lÃ©charge l'image brute
        # stream=True permet de ne pas tout charger d'un coup si l'image est Ã©norme
        resp = requests.get(url, stream=True, headers={'User-Agent': 'Mozilla/5.0'})
                
        # 2. On transforme les octets en tableau NumPy
        image_array = np.asarray(bytearray(resp.content), dtype=np.uint8)
        
        # 3. On dÃ©code l'image pour OpenCV (0 = Noir et Blanc direct, idÃ©al pour SIFT)
        img = cv2.imdecode(image_array, 0)
        
        return img
    except Exception as e:
        print(f"Erreur de tÃ©lÃ©chargement pour {url}: {e}")
        return None


def process_one_card(row_data):
    index, row = row_data
    image_path = row['image'].strip()
    print("image_path:", image_path)
    
    print("card_id:", image_path)
    image_path = url_to_image(image_path)
    if image_path is not None:
        keypoints, descriptors = orb.detectAndCompute(image_path, None)
        if descriptors is not None and len(keypoints) > 10:
            # On n'a mÃªme pas besoin de sauvegarder les Keypoints (kp) pour la BDD
            # On sauvegarde JUSTE les descripteurs (des) et l'ID.
            # "des" est en uint8 (8 bits) au lieu de float32 (32 bits) -> 4x plus lÃ©ger !
            return {
                'id': f"{row['number']}-{row['name']}-{row['set_name']}",
                'descriptors': descriptors
            }

if __name__ == '__main__':
    db_file = 'bdd/pokemon_card_bdd.csv' 
    df = pd.read_csv(db_file, sep=';')
    df.columns = df.columns.str.strip()
    
    tasks = list(df.iterrows())
    print("ðŸš€ DÃ©marrage Indexation ORB (Rapide & LÃ©ger)...")
    
    with ThreadPoolExecutor(max_workers=50) as executor:
        results = list(tqdm(executor.map(process_one_card, tasks), total=len(tasks)))
        

    valid_results = [r for r in results if r is not None]
    print(f"âœ… TerminÃ© ! {len(valid_results)} cartes indexÃ©es.")
    
    # Sauvegarde
    with open("orb_db.pkl", 'wb') as f:
        pickle.dump(valid_results, f)
    
    print("ðŸ’¾ Base de donnÃ©es 'orb_db.pkl' crÃ©Ã©e (devrait faire ~200-300 Mo).")

